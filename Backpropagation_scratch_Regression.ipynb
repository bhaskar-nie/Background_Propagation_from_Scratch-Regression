{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XsaG9bkTt_MF"
      },
      "outputs": [],
      "source": [
        " import pandas as pd\n",
        " import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df  = pd.DataFrame([[8, 8, 4], [7, 9, 5], [6, 10, 6], [5, 12, 7]], columns = ['CGPA', 'ATS Score', 'Package(LPA)'])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "naREqWDtuSla",
        "outputId": "c999d1b2-5bcd-450b-cdd5-fd6672ae1891"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   CGPA  ATS Score  Package(LPA)\n",
              "0     8          8             4\n",
              "1     7          9             5\n",
              "2     6         10             6\n",
              "3     5         12             7"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1db1e6bc-5924-4bbf-9704-b257d7a69503\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CGPA</th>\n",
              "      <th>ATS Score</th>\n",
              "      <th>Package(LPA)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1db1e6bc-5924-4bbf-9704-b257d7a69503')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1db1e6bc-5924-4bbf-9704-b257d7a69503 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1db1e6bc-5924-4bbf-9704-b257d7a69503');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cd1acb2d-b8f5-4b25-9ec4-c8238f5072af\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cd1acb2d-b8f5-4b25-9ec4-c8238f5072af')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cd1acb2d-b8f5-4b25-9ec4-c8238f5072af button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_411b53ba-fa6f-4a1d-91d5-5b075799a6a6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_411b53ba-fa6f-4a1d-91d5-5b075799a6a6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"CGPA\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 5,\n        \"max\": 8,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          7,\n          5,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ATS Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 8,\n        \"max\": 12,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          9,\n          12,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Package(LPA)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 4,\n        \"max\": 7,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          5,\n          7,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_parameters(layer_dimensions):\n",
        "    # Set a fixed random seed to make the results reproducible\n",
        "    np.random.seed(3)\n",
        "\n",
        "    # Create an empty dictionary to store the weight and bias parameters\n",
        "    parameters = {}\n",
        "\n",
        "    # Get the number of layers in the network (including input and output layers)\n",
        "    L = len(layer_dimensions)\n",
        "\n",
        "    # Loop through layers 1 to L-1 (we skip layer 0 because it's the input layer)\n",
        "    for l in range(1, L):\n",
        "        # Initialize weights for layer l with small values (here all 0.1 for simplicity)\n",
        "        # Shape: (number of neurons in previous layer, number of neurons in current layer)\n",
        "        parameters['W' + str(l)] = np.ones((layer_dimensions[l - 1], layer_dimensions[l])) * 0.1\n",
        "\n",
        "        # Initialize biases for layer l with zeros\n",
        "        # Shape: (number of neurons in current layer, 1)\n",
        "        parameters['b' + str(l)] = np.zeros((layer_dimensions[l], 1))\n",
        "\n",
        "    # Return the dictionary containing all the initialized parameters\n",
        "    return parameters"
      ],
      "metadata": {
        "id": "lhvFxG9NuxNd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_forward(A_prev, W, b):\n",
        "    # Compute the linear part of a layer's forward propagation\n",
        "    # A_prev: activations from the previous layer (shape: size of previous layer x number of examples)\n",
        "    # W: weights matrix for the current layer (shape: size of previous layer x size of current layer)\n",
        "    # b: bias vector for the current layer (shape: size of current layer x 1)\n",
        "\n",
        "    # Compute the linear transformation Z = W^T * A_prev + b\n",
        "    # Note: W.T is used because we want the shape to be (size of current layer x number of examples)\n",
        "    Z = np.dot(W.T, A_prev) + b\n",
        "\n",
        "    # Return the result of the linear transformation (Z)\n",
        "    return Z"
      ],
      "metadata": {
        "id": "3FwSaa0Q0zCh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main Forward Propagation function for a single row instance (i.e., one data sample)\n",
        "def L_layer_forward(X, parameters):\n",
        "    # X: input vector of shape (input size, 1) - i.e., a single column (one data instance)\n",
        "    # parameters: dictionary containing all the weights and biases for each layer\n",
        "\n",
        "    A = X  # Initial activation is the input feature vector\n",
        "    L = len(parameters) // 2  # Number of layers in the network (each has W and b)\n",
        "\n",
        "    # Loop through all the layers in the network\n",
        "    for l in range(1, L + 1):\n",
        "        A_prev = A  # Store previous activation for computing current layer's activation\n",
        "\n",
        "        # Retrieve current layer's weights and bias\n",
        "        Wl = parameters['W' + str(l)]\n",
        "        bl = parameters['b' + str(l)]\n",
        "\n",
        "        # Perform linear forward computation: Z = W.T @ A_prev + b\n",
        "        # NOTE: Your 'W' is stored as shape (prev_layer, current_layer), so we need W.T\n",
        "        A = linear_forward(A_prev, Wl, bl)\n",
        "\n",
        "        # Optional debugging prints:\n",
        "        print(\"A\" + str(l-1) + \": \", A_prev)\n",
        "        print(\"W\" + str(l) + \": \", Wl)\n",
        "        print(\"b\" + str(l) + \": \", bl)\n",
        "        print(\"A\" + str(l) + \": \", A)\n",
        "        print(\"--\" * 20)\n",
        "\n",
        "    # Return final output (last activation), and the last activation before it (optional)\n",
        "    return A, A_prev\n"
      ],
      "metadata": {
        "id": "s32JXYUh10jq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the first row's input features ('CGPA' and 'ATS Score') from the DataFrame\n",
        "# .values[0] gives the first row as a NumPy array → shape will be (2,)\n",
        "# .reshape(2, 1) converts it to a column vector of shape (2,1), which is required for our neural network\n",
        "X = df[['CGPA', 'ATS Score']].values[0].reshape(2, 1)\n",
        "\n",
        "# Extract the actual output (label) corresponding to the first row: 'Package(LPA)'\n",
        "# .values[0][0] gives the scalar value from the first row, first column\n",
        "y = df[['Package(LPA)']].values[0][0]\n",
        "\n",
        "# Initialize neural network parameters (weights and biases) for a 3-layer network:\n",
        "# - 2 input neurons (for CGPA and ATS Score)\n",
        "# - 2 hidden neurons in the first hidden layer\n",
        "# - 1 output neuron (for predicting Package)\n",
        "# All weights are initialized to 0.1, and all biases to 0\n",
        "parameters = initialize_parameters([2, 2, 1])\n",
        "\n",
        "# Print the initialized parameters to verify their structure\n",
        "parameters\n",
        "\n",
        "# Perform a full forward pass through the network using the input X and the initialized parameters\n",
        "# This will compute activations at each layer and finally give the output prediction\n",
        "y_hat,A1 = L_layer_forward(X, parameters)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Li4zJnpcBjqL",
        "outputId": "0522845e-bf0e-4d04-a14e-d00faedc9fe9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A0:  [[8]\n",
            " [8]]\n",
            "W1:  [[0.1 0.1]\n",
            " [0.1 0.1]]\n",
            "b1:  [[0.]\n",
            " [0.]]\n",
            "A1:  [[1.6]\n",
            " [1.6]]\n",
            "----------------------------------------\n",
            "A1:  [[1.6]\n",
            " [1.6]]\n",
            "W2:  [[0.1]\n",
            " [0.1]]\n",
            "b2:  [[0.]]\n",
            "A2:  [[0.32]]\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Above:\n",
        "# A0 = [8, 8] — This is the input vector (features from the first row of the dataset)\n",
        "# W1 = Weights for Layer 1 — These connect the input layer to the first hidden layer\n",
        "# b1 = [b11, b12] — Biases for the neurons in hidden layer 1\n",
        "\n",
        "# These are passed to linear_forward(A_prev, W1, b1) which computes:\n",
        "# Z1 = W1.T @ A0 + b1\n",
        "# A1 = Z1 in this case (since there's no activation function yet), so:\n",
        "# A1 = [O11, O12] — outputs from the first hidden layer (linear combinations)\n",
        "\n",
        "# Next layer:\n",
        "# A1 is now passed as input to the next layer with W2, b2 to get:\n",
        "# A2 = [O21] — the output from the final layer (the prediction)\n",
        "\n",
        "# The function L_layer_forward returns:\n",
        "# - A2: the final output (predicted Package)\n",
        "# - A1: the activation from the previous layer (needed for backprop)\n",
        "\n",
        "# WHY RETURN A_prev TOO?\n",
        "# During backpropagation, we compute gradients like:\n",
        "# ∂L/∂W = A_prev.T @ dZ\n",
        "# That’s why we need the activations of the previous layer (A_prev or Oij values)\n",
        "# They're essential for calculating the gradients during the backward pass."
      ],
      "metadata": {
        "id": "SrAdbO1wErJO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_hat is the final output returned from the forward propagation:\n",
        "# It's a 2D array with shape (1, 1), something like: [[value]]\n",
        "# To convert it into a plain scalar value (float), we extract the single element\n",
        "y_hat = y_hat[0][0]\n",
        "# A1 is the output from the hidden layer (before applying any activation, in your current setup).\n",
        "# This matrix contains the values computed after the first linear transformation:\n",
        "# A1 = W1.T @ A0 + b1\n",
        "# These are useful not only for forward pass inspection but also critical in backpropagation\n",
        "# since gradients depend on the activations from previous layers.\n",
        "A1\n",
        "#This will output something like: array([[O11], [O12]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YA3UAID6FXnE",
        "outputId": "fad63d05-ef40-4317-9f04-b144c8eb1543"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.6],\n",
              "       [1.6]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def update_parameters(parameters, y, y_hat, A1, X):\n",
        "    # Compute the gradient of Mean Squared Error (MSE) Loss w.r.t y_hat:\n",
        "    # dL/dy_hat = 2 * (y - y_hat)\n",
        "    # Learning rate is hardcoded as 0.001 here\n",
        "\n",
        "    # ================== Layer 2 (Output Layer) Updates ==================\n",
        "\n",
        "    # W2[0][0] is the weight connecting A1[0] to the output neuron\n",
        "    # Gradient: dL/dW2 = dL/dy_hat * d(y_hat)/dW2 = 2*(y - y_hat) * A1[i]\n",
        "    parameters['W2'][0][0] += 0.001 * 2 * (y - y_hat) * A1[0][0]\n",
        "\n",
        "    # W2[1][0] connects A1[1] to output\n",
        "    parameters['W2'][1][0] += 0.001 * 2 * (y - y_hat) * A1[1][0]\n",
        "\n",
        "    # Bias b2 — add gradient: dL/db2 = 2 * (y - y_hat)\n",
        "    parameters['b2'][0][0] += 0.001 * 2 * (y - y_hat)\n",
        "\n",
        "    # ================== Layer 1 (Hidden Layer) Updates ==================\n",
        "\n",
        "    # The hidden layer gradients are approximated manually here:\n",
        "    # W1[0][0] is the weight from X[0] to A1[0], which connects to output via W2[0][0]\n",
        "    # So, its gradient flows back via W2[0][0] path\n",
        "    parameters['W1'][0][0] += 0.001 * 2 * (y - y_hat) * parameters['W2'][0][0] * X[0][0]\n",
        "\n",
        "    # W1[0][1] connects X[1] to A1[0]\n",
        "    parameters['W1'][0][1] += 0.001 * 2 * (y - y_hat) * parameters['W2'][0][0] * X[1][0]\n",
        "\n",
        "    # Bias for neuron A1[0]\n",
        "    parameters['b1'][0][0] += 0.001 * 2 * (y - y_hat) * parameters['W2'][0][0]\n",
        "\n",
        "    # W1[1][0] connects X[0] to A1[1], which connects to output via W2[1][0]\n",
        "    parameters['W1'][1][0] += 0.001 * 2 * (y - y_hat) * parameters['W2'][1][0] * X[0][0]\n",
        "\n",
        "    # W1[1][1] connects X[1] to A1[1]\n",
        "    parameters['W1'][1][1] += 0.001 * 2 * (y - y_hat) * parameters['W2'][1][0] * X[1][0]\n",
        "\n",
        "    # Bias for neuron A1[1]\n",
        "    parameters['b1'][1][0] += 0.001 * 2 * (y - y_hat) * parameters['W2'][1][0]\n"
      ],
      "metadata": {
        "id": "a6Yn61wdJEw8"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the parameter update function with the following:\n",
        "# parameters: current weights and biases\n",
        "# y: actual label (Package value for this instance)\n",
        "# y_hat: predicted output from forward propagation\n",
        "# A1: activations (outputs) from the hidden layer\n",
        "# X: input feature vector (CGPA, ATS Score for this row)\n",
        "update_parameters(parameters, y, y_hat, A1, X)"
      ],
      "metadata": {
        "id": "hIO0vWxFJthP"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After the update, print or inspect the updated parameters dictionary\n",
        "# This dictionary contains the learned weights and biases for both layers:\n",
        "#   - 'W1' and 'b1' are for the layer between input and hidden layer\n",
        "#   - 'W2' and 'b2' are for the layer between hidden layer and output\n",
        "# Since one step of gradient descent has been applied, their values should now be\n",
        "# slightly different from their initial values (e.g., 0.1 or 0.0)\n",
        "parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tnioUjEKRiC",
        "outputId": "f86fe1ee-ca71-4eb7-e28c-c345b49c3329"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'W1': array([[0.13249307, 0.13781791],\n",
              "        [0.1325153 , 0.1378465 ]]),\n",
              " 'b1': array([[0.00439444],\n",
              "        [0.00439761]]),\n",
              " 'W2': array([[0.15747535],\n",
              "        [0.15783471]]),\n",
              " 'b2': array([[0.03262821]])}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract input features for the second training example (index 1)\n",
        "X = df[['CGPA', 'ATS Score']].values[1].reshape(2, 1) # Shape(no of features, no. of training exaplme)\n",
        "y = df[['Package(LPA)']].values[1][0]\n",
        "\n",
        "y_hat,A1 = L_layer_forward(X,parameters)\n",
        "y_hat = y_hat[0][0]\n",
        "\n",
        "parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKJLDPZSKTyr",
        "outputId": "3a2c88d2-59c7-4372-9466-b205015c7e74"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A0:  [[7]\n",
            " [9]]\n",
            "W1:  [[0.13249307 0.13781791]\n",
            " [0.1325153  0.1378465 ]]\n",
            "b1:  [[0.00439444]\n",
            " [0.00439761]]\n",
            "A1:  [[2.12448363]\n",
            " [2.20974148]]\n",
            "----------------------------------------\n",
            "A1:  [[2.12448363]\n",
            " [2.20974148]]\n",
            "W2:  [[0.15747535]\n",
            " [0.15783471]]\n",
            "b2:  [[0.03262821]]\n",
            "A2:  [[0.71595594]]\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'W1': array([[0.13249307, 0.13781791],\n",
              "        [0.1325153 , 0.1378465 ]]),\n",
              " 'b1': array([[0.00439444],\n",
              "        [0.00439761]]),\n",
              " 'W2': array([[0.15747535],\n",
              "        [0.15783471]]),\n",
              " 'b2': array([[0.03262821]])}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "update_parameters(parameters,y,y_hat,A1,X)\n",
        "parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3Htftd5Ld7l",
        "outputId": "b5aa55be-97b7-4154-d061-b4f9bd15981e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'W1': array([[0.14302965, 0.15136494],\n",
              "        [0.14311725, 0.15147757]]),\n",
              " 'b1': array([[0.00589966],\n",
              "        [0.00591218]]),\n",
              " 'W2': array([[0.17567812],\n",
              "        [0.17676797]]),\n",
              " 'b2': array([[0.0411963]])}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract input features for the third training example (index 2)\n",
        "X = df[['CGPA', 'ATS Score']].values[2].reshape(2, 1) # Shape(no of features, no. of training exaplme)\n",
        "y = df[['Package(LPA)']].values[2][0]\n",
        "\n",
        "y_hat,A1 = L_layer_forward(X,parameters)\n",
        "y_hat = y_hat[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNesxQL4L74n",
        "outputId": "5b9efed9-bfc0-49c4-b0da-c5563a7ca0b9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A0:  [[ 6]\n",
            " [10]]\n",
            "W1:  [[0.15528401 0.17178888]\n",
            " [0.15552293 0.1721537 ]]\n",
            "b1:  [[0.00794206]\n",
            " [0.00797979]]\n",
            "A1:  [[2.49487538]\n",
            " [2.76025011]]\n",
            "----------------------------------------\n",
            "A1:  [[2.49487538]\n",
            " [2.76025011]]\n",
            "W2:  [[0.19921008]\n",
            " [0.20166995]]\n",
            "b2:  [[0.05144876]]\n",
            "A2:  [[1.10511257]]\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "update_parameters(parameters,y,y_hat,A1,X)\n",
        "parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfqmlylhmFF6",
        "outputId": "ee099836-1acb-4759-ac33-1bc7fd6eb760"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'W1': array([[0.16841999, 0.19368218],\n",
              "        [0.168956  , 0.19454215]]),\n",
              " 'b1': array([[0.01013139],\n",
              "        [0.01021863]]),\n",
              " 'W2': array([[0.22363435],\n",
              "        [0.22869217]]),\n",
              " 'b2': array([[0.06123854]])}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract input features for the 4th training example (index 2)\n",
        "X = df[['CGPA', 'ATS Score']].values[3].reshape(2, 1) # Shape(no of features, no. of training exaplme)\n",
        "y = df[['Package(LPA)']].values[3][0]\n",
        "\n",
        "y_hat,A1 = L_layer_forward(X,parameters)\n",
        "y_hat = y_hat[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b6D1wGvmJZp",
        "outputId": "e659fc50-ee4f-4c49-95bc-499227e67363"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A0:  [[ 5]\n",
            " [12]]\n",
            "W1:  [[0.16841999 0.19368218]\n",
            " [0.168956   0.19454215]]\n",
            "b1:  [[0.01013139]\n",
            " [0.01021863]]\n",
            "A1:  [[2.87970328]\n",
            " [3.31313536]]\n",
            "----------------------------------------\n",
            "A1:  [[2.87970328]\n",
            " [3.31313536]]\n",
            "W2:  [[0.22363435]\n",
            " [0.22869217]]\n",
            "b2:  [[0.06123854]]\n",
            "A2:  [[1.46292723]]\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "update_parameters(parameters,y,y_hat,A1,X)\n",
        "parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCGQnqt0mfeM",
        "outputId": "9832cb2b-da62-440b-9679-1e823f9bcb05"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'W1': array([[0.18256857, 0.22763878],\n",
              "        [0.18365041, 0.22980874]]),\n",
              " 'b1': array([[0.0129611 ],\n",
              "        [0.01315752]]),\n",
              " 'W2': array([[0.2555246 ],\n",
              "        [0.26538232]]),\n",
              " 'b2': array([[0.07231268]])}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Till now, the whole dataset got trained for 1 time(1 epoch)\n",
        "# Let's start with epoch implementation"
      ],
      "metadata": {
        "id": "pQ_mJrqfnMIi"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize parameters before training\n",
        "# Input layer: 2 neurons (CGPA, Profile Score)\n",
        "# Hidden layer: 2 neurons\n",
        "# Output layer: 1 neuron (Predicted LPA)\n",
        "parameters = initialize_parameters([2, 2, 1])\n",
        "\n",
        "# Set the number of epochs — how many times the entire dataset is processed\n",
        "epochs = 5\n"
      ],
      "metadata": {
        "id": "il4actWRnFTm"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Outer loop: iterate through entire dataset multiple times (epochs)\n",
        "for i in range(epochs):\n",
        "\n",
        "    # Initialize list to track loss for the current epoch\n",
        "    Loss = []\n",
        "\n",
        "    # Inner loop: iterate through each training example (row in the DataFrame)\n",
        "    for j in range(df.shape[0]):\n",
        "\n",
        "        # Extract input vector X for j-th training sample\n",
        "        # Reshape to (features, 1) => column vector\n",
        "        X = df[['CGPA', 'ATS Score']].values[j].reshape(2, 1)\n",
        "\n",
        "        # Extract actual output (LPA) for j-th training sample\n",
        "        y = df[['Package(LPA)']].values[j][0]\n",
        "\n",
        "        # Perform forward pass — get prediction and hidden layer output\n",
        "        y_hat, A1 = L_layer_forward(X, parameters)\n",
        "\n",
        "        # Flatten the prediction output (from 2D to scalar)\n",
        "        y_hat = y_hat[0][0]\n",
        "\n",
        "        # Backward pass — update weights and biases based on prediction error\n",
        "        update_parameters(parameters, y, y_hat, A1, X)\n",
        "\n",
        "        # Calculate squared error and add to Loss list\n",
        "        Loss.append((y - y_hat) ** 2)\n",
        "\n",
        "    # After processing all samples in this epoch, print the average loss\n",
        "    print('Epoch -', i + 1, 'Loss -', np.array(Loss).mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvnSDKhtmirk",
        "outputId": "7c6f75a7-4aae-46e2-9fe7-4d9aec3ebce5"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A0:  [[8]\n",
            " [8]]\n",
            "W1:  [[0.1 0.1]\n",
            " [0.1 0.1]]\n",
            "b1:  [[0.]\n",
            " [0.]]\n",
            "A1:  [[1.6]\n",
            " [1.6]]\n",
            "----------------------------------------\n",
            "A1:  [[1.6]\n",
            " [1.6]]\n",
            "W2:  [[0.1]\n",
            " [0.1]]\n",
            "b2:  [[0.]]\n",
            "A2:  [[0.32]]\n",
            "----------------------------------------\n",
            "A0:  [[7]\n",
            " [9]]\n",
            "W1:  [[0.10658137 0.10658137]\n",
            " [0.10658137 0.10658137]]\n",
            "b1:  [[0.00082267]\n",
            " [0.00082267]]\n",
            "A1:  [[1.70612461]\n",
            " [1.70612461]]\n",
            "----------------------------------------\n",
            "A1:  [[1.70612461]\n",
            " [1.70612461]]\n",
            "W2:  [[0.111776]\n",
            " [0.111776]]\n",
            "b2:  [[0.00736]]\n",
            "A2:  [[0.38876757]]\n",
            "----------------------------------------\n",
            "A0:  [[ 6]\n",
            " [10]]\n",
            "W1:  [[0.11481311 0.11716504]\n",
            " [0.11481311 0.11716504]]\n",
            "b1:  [[0.00199863]\n",
            " [0.00199863]]\n",
            "A1:  [[1.83900839]\n",
            " [1.8766392 ]]\n",
            "----------------------------------------\n",
            "A1:  [[1.83900839]\n",
            " [1.8766392 ]]\n",
            "W2:  [[0.12751067]\n",
            " [0.12751067]]\n",
            "b2:  [[0.01658246]]\n",
            "A2:  [[0.49036719]]\n",
            "----------------------------------------\n",
            "A0:  [[ 5]\n",
            " [12]]\n",
            "W1:  [[0.12458335 0.13344878]\n",
            " [0.12461077 0.13349447]]\n",
            "b1:  [[0.00362701]\n",
            " [0.00363158]]\n",
            "A1:  [[2.12187303]\n",
            " [2.2728091 ]]\n",
            "----------------------------------------\n",
            "A1:  [[2.12187303]\n",
            " [2.2728091 ]]\n",
            "W2:  [[0.1477752 ]\n",
            " [0.14818986]]\n",
            "b2:  [[0.02760173]]\n",
            "A2:  [[0.6779692]]\n",
            "----------------------------------------\n",
            "Epoch - 1 Loss - 26.28249792398698\n",
            "A0:  [[8]\n",
            " [8]]\n",
            "W1:  [[0.13562189 0.15994127]\n",
            " [0.13579618 0.16033944]]\n",
            "b1:  [[0.00583472]\n",
            " [0.00586866]]\n",
            "A1:  [[2.17717925]\n",
            " [2.56811431]]\n",
            "----------------------------------------\n",
            "A1:  [[2.17717925]\n",
            " [2.56811431]]\n",
            "W2:  [[0.17460429]\n",
            " [0.1769274 ]]\n",
            "b2:  [[0.04024579]]\n",
            "A2:  [[0.87476041]]\n",
            "----------------------------------------\n",
            "A0:  [[7]\n",
            " [9]]\n",
            "W1:  [[0.14503325 0.16935262]\n",
            " [0.14544588 0.16998915]]\n",
            "b1:  [[0.00701114]\n",
            " [0.00707487]]\n",
            "A1:  [[2.33125681]\n",
            " [2.72244555]]\n",
            "----------------------------------------\n",
            "A1:  [[2.33125681]\n",
            " [2.72244555]]\n",
            "W2:  [[0.1882127 ]\n",
            " [0.19297934]]\n",
            "b2:  [[0.04649627]]\n",
            "A2:  [[1.01064417]]\n",
            "----------------------------------------\n",
            "A0:  [[ 6]\n",
            " [10]]\n",
            "W1:  [[0.15658396 0.18420354]\n",
            " [0.15743714 0.18540648]]\n",
            "b1:  [[0.00866124]\n",
            " [0.00878791]]\n",
            "A1:  [[2.52253643]\n",
            " [2.96807397]]\n",
            "----------------------------------------\n",
            "A1:  [[2.52253643]\n",
            " [2.96807397]]\n",
            "W2:  [[0.20681313]\n",
            " [0.21470095]]\n",
            "b2:  [[0.05447498]]\n",
            "A2:  [[1.21341694]]\n",
            "----------------------------------------\n",
            "A0:  [[ 5]\n",
            " [12]]\n",
            "W1:  [[0.16985018 0.2063139 ]\n",
            " [0.17140141 0.20868027]]\n",
            "b1:  [[0.01087227]\n",
            " [0.01111529]]\n",
            "A1:  [[2.91694011]\n",
            " [3.54684797]]\n",
            "----------------------------------------\n",
            "A1:  [[2.91694011]\n",
            " [3.54684797]]\n",
            "W2:  [[0.23096179]\n",
            " [0.24311482]]\n",
            "b2:  [[0.06404815]]\n",
            "A2:  [[1.60004115]]\n",
            "----------------------------------------\n",
            "Epoch - 2 Loss - 19.438253848220803\n",
            "A0:  [[8]\n",
            " [8]]\n",
            "W1:  [[0.18402315 0.24032904]\n",
            " [0.186598   0.24515208]]\n",
            "b1:  [[0.01370687]\n",
            " [0.01415461]]\n",
            "A1:  [[2.97867611]\n",
            " [3.89800358]]\n",
            "----------------------------------------\n",
            "A1:  [[2.97867611]\n",
            " [3.89800358]]\n",
            "W2:  [[0.2624645 ]\n",
            " [0.28142048]]\n",
            "b2:  [[0.07484807]]\n",
            "A2:  [[1.95362286]]\n",
            "----------------------------------------\n",
            "A0:  [[7]\n",
            " [9]]\n",
            "W1:  [[0.19301593 0.24932182]\n",
            " [0.19633463 0.25488871]]\n",
            "b1:  [[0.01483097]\n",
            " [0.01537168]]\n",
            "A1:  [[3.1329542 ]\n",
            " [4.05462284]]\n",
            "----------------------------------------\n",
            "A1:  [[3.1329542 ]\n",
            " [4.05462284]]\n",
            "W2:  [[0.27465549]\n",
            " [0.29737405]]\n",
            "b2:  [[0.07894082]]\n",
            "A2:  [[2.14516353]]\n",
            "----------------------------------------\n",
            "A0:  [[ 6]\n",
            " [10]]\n",
            "W1:  [[0.20470823 0.26435477]\n",
            " [0.20914527 0.27135953]]\n",
            "b1:  [[0.01650129]\n",
            " [0.01720178]]\n",
            "A1:  [[3.33620338]\n",
            " [4.31692573]]\n",
            "----------------------------------------\n",
            "A1:  [[3.33620338]\n",
            " [4.31692573]]\n",
            "W2:  [[0.29254364]\n",
            " [0.32052462]]\n",
            "b2:  [[0.08465049]]\n",
            "A2:  [[2.44431656]]\n",
            "----------------------------------------\n",
            "A0:  [[ 5]\n",
            " [12]]\n",
            "W1:  [[0.21820284 0.2868458 ]\n",
            " [0.22413136 0.29633635]]\n",
            "b1:  [[0.0187504 ]\n",
            " [0.01969946]]\n",
            "A1:  [[3.79934094]\n",
            " [5.00996462]]\n",
            "----------------------------------------\n",
            "A1:  [[3.79934094]\n",
            " [5.00996462]]\n",
            "W2:  [[0.3162686 ]\n",
            " [0.35122387]]\n",
            "b2:  [[0.09176186]]\n",
            "A2:  [[3.05299325]]\n",
            "----------------------------------------\n",
            "Epoch - 3 Loss - 10.139874435827522\n",
            "A0:  [[8]\n",
            " [8]]\n",
            "W1:  [[0.23186978 0.31964643]\n",
            " [0.23955518 0.33335352]]\n",
            "b1:  [[0.02148378]\n",
            " [0.02278422]]\n",
            "A1:  [[3.79288343]\n",
            " [5.24678381]]\n",
            "----------------------------------------\n",
            "A1:  [[3.79288343]\n",
            " [5.24678381]]\n",
            "W2:  [[0.34626065]\n",
            " [0.39077259]]\n",
            "b2:  [[0.09965587]]\n",
            "A2:  [[3.46328148]]\n",
            "----------------------------------------\n",
            "A0:  [[7]\n",
            " [9]]\n",
            "W1:  [[0.23487825 0.32265491]\n",
            " [0.2429593  0.33675764]]\n",
            "b1:  [[0.02185984]\n",
            " [0.02320974]]\n",
            "A1:  [[3.85264134]\n",
            " [5.31261285]]\n",
            "----------------------------------------\n",
            "A1:  [[3.85264134]\n",
            " [5.31261285]]\n",
            "W2:  [[0.35033207]\n",
            " [0.39640469]]\n",
            "b2:  [[0.10072931]]\n",
            "A2:  [[3.55637777]]\n",
            "----------------------------------------\n",
            "A0:  [[ 6]\n",
            " [10]]\n",
            "W1:  [[0.24218353 0.3320474 ]\n",
            " [0.25128093 0.34745688]]\n",
            "b1:  [[0.02290345]\n",
            " [0.02439854]]\n",
            "A1:  [[3.98881394]\n",
            " [5.49125174]]\n",
            "----------------------------------------\n",
            "A1:  [[3.98881394]\n",
            " [5.49125174]]\n",
            "W2:  [[0.36145559]\n",
            " [0.4117435 ]]\n",
            "b2:  [[0.10361656]]\n",
            "A2:  [[3.80638285]]\n",
            "----------------------------------------\n",
            "A0:  [[ 5]\n",
            " [12]]\n",
            "W1:  [[0.25215892 0.34867307]\n",
            " [0.26275359 0.36657798]]\n",
            "b1:  [[0.02456602]\n",
            " [0.02631065]]\n",
            "A1:  [[4.43840374]\n",
            " [6.16861171]]\n",
            "----------------------------------------\n",
            "A1:  [[4.43840374]\n",
            " [6.16861171]]\n",
            "W2:  [[0.37895545]\n",
            " [0.43583491]]\n",
            "b2:  [[0.10800379]]\n",
            "A2:  [[4.47845739]]\n",
            "----------------------------------------\n",
            "Epoch - 4 Loss - 3.385561305106485\n",
            "A0:  [[8]\n",
            " [8]]\n",
            "W1:  [[0.26227885 0.37296089]\n",
            " [0.27452778 0.39483602]]\n",
            "b1:  [[0.02659   ]\n",
            " [0.02866549]]\n",
            "A1:  [[4.32104303]\n",
            " [6.17104077]]\n",
            "----------------------------------------\n",
            "A1:  [[4.32104303]\n",
            " [6.17104077]]\n",
            "W2:  [[0.4013387 ]\n",
            " [0.46694374]]\n",
            "b2:  [[0.11304688]]\n",
            "A2:  [[4.72877753]]\n",
            "----------------------------------------\n",
            "A0:  [[7]\n",
            " [9]]\n",
            "W1:  [[0.2576725  0.36835454]\n",
            " [0.26918789 0.38949613]]\n",
            "b1:  [[0.02601421]\n",
            " [0.027998  ]]\n",
            "A1:  [[4.25241274]\n",
            " [6.111945  ]]\n",
            "----------------------------------------\n",
            "A1:  [[4.25241274]\n",
            " [6.111945  ]]\n",
            "W2:  [[0.39504054]\n",
            " [0.45794911]]\n",
            "b2:  [[0.11158932]]\n",
            "A2:  [[4.59042452]]\n",
            "----------------------------------------\n",
            "A0:  [[ 6]\n",
            " [10]]\n",
            "W1:  [[0.25995766 0.3712926 ]\n",
            " [0.2718425  0.39290921]]\n",
            "b1:  [[0.02634066]\n",
            " [0.02837723]]\n",
            "A1:  [[4.30451167]\n",
            " [6.18522495]]\n",
            "----------------------------------------\n",
            "A1:  [[4.30451167]\n",
            " [6.18522495]]\n",
            "W2:  [[0.39852391]\n",
            " [0.46295572]]\n",
            "b2:  [[0.11240847]]\n",
            "A2:  [[4.69134453]]\n",
            "----------------------------------------\n",
            "A0:  [[ 5]\n",
            " [12]]\n",
            "W1:  [[0.26639295 0.38201809]\n",
            " [0.27936692 0.40544991]]\n",
            "b1:  [[0.02741321]\n",
            " [0.0296313 ]]\n",
            "A1:  [[4.71178104]\n",
            " [6.80512062]]\n",
            "----------------------------------------\n",
            "A1:  [[4.71178104]\n",
            " [6.80512062]]\n",
            "W2:  [[0.40979015]\n",
            " [0.47914437]]\n",
            "b2:  [[0.11502578]]\n",
            "A2:  [[5.30650251]]\n",
            "----------------------------------------\n",
            "Epoch - 5 Loss - 1.3198454128484565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After all epochs, print the final learned parameters\n",
        "# These include W1, b1, W2, b2 after being refined over 5 epochs\n",
        "parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xz2p4wQem_d_",
        "outputId": "5da2d8c4-8950-4008-d074-a26af585f19d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'W1': array([[0.273603  , 0.3993222 ],\n",
              "        [0.28787155, 0.42586102]]),\n",
              " 'b1': array([[0.02885522],\n",
              "        [0.03133223]]),\n",
              " 'W2': array([[0.42574893],\n",
              "        [0.50219328]]),\n",
              " 'b2': array([[0.11841278]])}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NOIJy6TIniAD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}